{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone: Text Factorizing with NLP\n",
    "## Thomas Ludlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Gensim LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains a prototype model flow for the Exploratory Data Analysis (EDA) process to prepare raw text data from 4 works of philosophy for Latent Dirichlet Allocation (LDA).  The output of this LDA will be a ranking of conceptual differences between works along with Dirichlet-prior similarity weights.  These weights will comprise the inputs for a Recurrent Neural Net model to assess multi-class similarity probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Data Science\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Natural Language Processing\n",
    "import spacy\n",
    "import gensim\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import ldamodel, CoherenceModel\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as pyplot\n",
    "%matplotlib inline\n",
    "\n",
    "# Override deprecation warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Book Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read files from disk\n",
    "plato_file = open('./data/plato_republic.txt','r')\n",
    "aristotle_file = open('./data/aristotle_categories.txt','r')\n",
    "descartes_file = open('./data/descartes_principles.txt','r')\n",
    "kant_file = open('./data/kant_critique.txt','r')\n",
    "\n",
    "# Convert files into list of lines\n",
    "plato = plato_file.readlines()\n",
    "aristotle = aristotle_file.readlines()\n",
    "descartes = descartes_file.readlines()\n",
    "kant = kant_file.readlines()\n",
    "\n",
    "# Strip publishing text from front and back\n",
    "plato_lines = plato[8494:24328]\n",
    "aristotle_lines = aristotle[37:1492]\n",
    "descartes_lines = descartes[362:-6]\n",
    "kant_lines = kant[27:-373]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_list = [plato_lines, \n",
    "            aristotle_lines, \n",
    "            descartes_lines, \n",
    "            kant_lines]\n",
    "\n",
    "raw_corpus = [' '.join(doc).replace('\\n','') for doc in doc_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_docs = len(doc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE REPUBLIC.     PERSONS OF THE DIALOGUE.  Socrates, who is the narrator.  Glaucon.  Adeimantus.  Polemarchus.  Cephalus.  Thrasymachus.  Cleitophon.  And others who are mute auditors.  The scene is  \n",
      "\n",
      "The Categories   By  Aristotle   Translated by E. M. Edghill    Section 1  Part 1  Things are said to be named 'equivocally' when, though they have a common name, the definition corresponding with the \n",
      "\n",
      "SELECTIONS FROM THE PRINCIPLES OF PHILOSOPHY  OF  RENE DESCARTES (1596-1650)  TRANSLATED BY JOHN VEITCH, LL. D. LATE PROFESSOR OF LOGIC AND RHETORIC IN THE UNIVERSITY OF GLASGOW     From the Publisher \n",
      "\n",
      " THE CRITIQUE OF PURE REASON   By Immanuel Kant    Translated by J. M. D. Meiklejohn   Contents   Preface to the First Edition (1781)    Preface to the Second Edition (1787)    Introduction    I. Of t \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_docs):\n",
    "    print(raw_corpus[i][:200], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**spaCy English Tokens, Lemma, Stopwords**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using smallest English library which does not include vectors\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.max_length = 1_500_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spaCy processing for tokens, lemma, part-of-speech, dependency\n",
    "docs_nlp = []\n",
    "\n",
    "for i in range(num_docs):\n",
    "    docs_nlp.append(nlp(raw_corpus[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_lemma = []\n",
    "\n",
    "for i in range(num_docs):\n",
    "    docs_lemma.append([token.lemma_ for token in docs_nlp[i] # List comprehension\n",
    "                       if token.lemma_ != '-PRON-'           # Pronouns are excluded\n",
    "                       and token.pos_ != 'PUNCT'             # Punctionation is excluded\n",
    "                       and token.is_alpha                    # Numbers are excluded\n",
    "                       and not token.is_stop])               # Stop words are excluded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'republic', 'person', 'of', 'the', 'dialogue', 'socrates', 'narrator', 'glaucon', 'adeimantus', 'polemarchus', 'cephalus', 'thrasymachus', 'cleitophon', 'and', 'mute', 'auditor', 'the', 'scene', 'lay'] \n",
      "\n",
      "['the', 'categories', 'by', 'aristotle', 'translate', 'edghill', 'section', 'part', 'thing', 'say', 'name', 'equivocally', 'common', 'definition', 'correspond', 'differ', 'thus', 'real', 'man', 'figure'] \n",
      "\n",
      "['selection', 'from', 'the', 'principle', 'of', 'philosophy', 'of', 'rene', 'descartes', 'translate', 'by', 'john', 'veitch', 'll', 'late', 'professor', 'of', 'logic', 'and', 'rhetoric'] \n",
      "\n",
      "['the', 'critique', 'of', 'pure', 'reason', 'by', 'immanuel', 'kant', 'translate', 'meiklejohn', 'contents', 'preface', 'first', 'edition', 'preface', 'second', 'edition', 'introduction', 'of', 'difference'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pre-processed text tokens\n",
    "\n",
    "for i in range(num_docs):\n",
    "    print(docs_lemma[i][:20], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gensim Dictionary and Corpus**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build dictionary to contain all terms from normalized text\n",
    "g_dict = Dictionary(docs_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 a \n",
      "\n",
      "1 abate \n",
      "\n",
      "2 abdera \n",
      "\n",
      "3 abhor \n",
      "\n",
      "4 abhorrence \n",
      "\n",
      "5 abide \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Each word is given an integer index value\n",
    "for i in range(6):\n",
    "    print(i, g_dict[i], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build corpus of normalized text relative to dictionary\n",
    "corpus = [g_dict.doc2bow(docs_lemma[i])\n",
    "          for doc in docs_lemma \n",
    "          for i in range(num_docs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 31), (1, 1), (2, 1), (3, 1), (4, 2)] \n",
      "\n",
      "[(0, 9), (5, 5), (6, 1), (18, 2), (35, 1)] \n",
      "\n",
      "[(0, 5), (6, 18), (14, 1), (17, 5), (18, 18)] \n",
      "\n",
      "[(0, 97), (5, 6), (6, 80), (8, 3), (12, 1)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Text words are indexed to source and dictionary values\n",
    "for i in range(num_docs):\n",
    "    print(corpus[i][:5], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gensim LDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of LDA model\n",
    "lda_model = ldamodel.LdaModel(corpus=corpus,\n",
    "                              id2word=g_dict,\n",
    "                              num_topics=4, \n",
    "                              random_state=131,\n",
    "                              update_every=1,\n",
    "                              chunksize=100,\n",
    "                              passes=10,\n",
    "                              alpha='auto',\n",
    "                              per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.019*\"conception\" + 0.015*\"reason\" + 0.014*\"object\" + 0.010*\"experience\" + 0.010*\"condition\" + 0.009*\"the\" + 0.009*\"time\" + 0.009*\"pure\" + 0.009*\"phenomenon\" + 0.009*\"thing\"'),\n",
       " (1,\n",
       "  '0.016*\"body\" + 0.015*\"thing\" + 0.010*\"mind\" + 0.009*\"god\" + 0.008*\"substance\" + 0.008*\"know\" + 0.008*\"truth\" + 0.007*\"nature\" + 0.007*\"place\" + 0.007*\"motion\"'),\n",
       " (2,\n",
       "  '0.026*\"say\" + 0.018*\"and\" + 0.013*\"good\" + 0.013*\"man\" + 0.011*\"true\" + 0.010*\"yes\" + 0.008*\"state\" + 0.006*\"like\" + 0.006*\"reply\" + 0.006*\"thing\"'),\n",
       " (3,\n",
       "  '0.017*\"man\" + 0.017*\"contrary\" + 0.015*\"case\" + 0.014*\"thing\" + 0.014*\"quality\" + 0.014*\"substance\" + 0.011*\"say\" + 0.010*\"subject\" + 0.010*\"for\" + 0.010*\"term\"')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Performance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Perplexity_ is a rating for model performance, with lower values scoring better.  This is calculated against the entire corpus, but can be used in a Train-Test Split to validate performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6.8968450046381315"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.log_perplexity(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Coherence_ measures human interpretability of the LDA results, and is calculated using probability calculations around the segmented topics.  Higher values are better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43383330894069172"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = CoherenceModel(model=lda_model, texts=docs_lemma, dictionary=g_dict, coherence='c_v')\n",
    "cm.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
